<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-size:32px;
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	pre {
        font-size: 16px; /* Adjust this value to change the font size */
        font-family: Consolas, "Courier New", monospace; /* This font family is similar to the one used in VSCode */
        background-color: #f4f4f4ec; /* This is the background color of VSCode's dark theme */
        color: #0f0f0f; /* This is the font color of VSCode's dark theme */
        padding: 10px;
        border-radius: 5px;
    }
</style>

<html>
<head>
	<title>DF40: Toward Next-Generation Deepfake Detection</title>
	<meta property="og:image" content="./images/df40_intro.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="DF40: Toward Next-Generation Deepfake Detection." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">DF40: Toward Next-Generation Deepfake Detection</span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:19px"><a href="https://yzy-stack.github.io/">Zhiyuan Yan</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:19px"><a href="https://sndler.github.io/">Taiping Yao</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:19px"><a href="https://chenshen.xyz/">Shen Chen</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:19px"><a href="https://openreview.net/profile?id=~Yandan_Zhao1/">Yandan Zhao</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:19px"><a href="https://openreview.net/profile?id=~Xinghe_Fu1/">Xinghe Fu</a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=800px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:19px"><a href="https://openreview.net/profile?id=~Junwei_Zhu1/">Junwei Zhu</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:19px"><a href="https://openreview.net/profile?id=~Donghao_Luo1/">Donghao Luo</a></span>
						</center>
					</td>
					<td align=center width=130px>
						<center>
							<span style="font-size:19px"><a href="https://openreview.net/profile?id=~Chengjie_Wang1/">Chengjie Wang</a></span>
						</center>
					</td>
					<td align=center width=130px>
						<center>
							<span style="font-size:19px"><a href="https://openreview.net/profile?id=~Shouhong_Ding3/">Shouhong Ding</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:19px"><a href="https://openreview.net/profile?id=~Yunsheng_Wu1/">Yunsheng Wu</a></span>
						</center>
					</td>
					<td align=center width=80px>
						<center>
							<span style="font-size:19px"><a href="https://yuanli2333.github.io/">Li Yuan</a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=400px>
				<tr>
					<td align=center width=110px>
						<center>
							<span style="font-size:24px">Paper</span> <span style="font-size:24px"><a href='https://arxiv.org/abs/2406.13495'>[ArXiv]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px">Code</span> <span style="font-size:24px"><a href='https://github.com/YZY-stack/DF40?tab=readme-ov-file'>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:700px; margin-top: 15; margin-bottom: 10;" src="./images/df40_intro.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>	
				</a> <span style="color:rgba(0, 81, 255, 0.852)"><strong>Is it possible to detect the various types of AI-generated faces (e.g., face-swapping, talking-head, AIGC, etcs)?</strong></span> This work proposes a comprehensive dataset called <strong>DF40</strong>, which comprises <strong>40 distinct synthesis techniques</strong>, including <i>10 face-swapping (FS), 12 face-reenactment (FR), 10 entire face synthesis (EFS), and 5 face editing (FE) methods</i>. We then conduct more than 2,000+ evaluations on a standard benchmark, leading to several new findings with insightful analysis. </a>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<center><h1>Why using DF40? (highlights)</h1></center>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<br> - <strong>Realism and diversity</strong>: DF40 contains the latest and most realistic synthesis techniques from various types such as <a href="https://www.heygen.com/">HeyGen</a> (FR), <a href="https://github.com/iperov/DeepFaceLab">DeepFaceLab</a> (FS), <a href="https://www.midjourney-v6.com/">MidJourney-v6</a> (EFS), <a href="https://ziqihuangg.github.io/projects/collaborative-diffusion.html/">Collaborative-Diffusion</a> (FE), etc.
					<br> - <strong>Multiple scenarios</strong>: DF40 contains 31 known/white-box synthesis methods (both the real data and fake methods are known) and 9 unknown/black-box methods (one of the real data and fake methods is unknown).
					<br> - <strong>Aligned data domain</strong>: the proposed 31 known/white-box methods are applied to the real data from the widely used <a href="https://github.com/ondyari/FaceForensics/">FF++</a> and <a href="https://github.com/yuezunli/celeb-deepfakeforensics/">Celeb-DF</a> datasets, meaning our generated fakes and their original fakes are from the same data domain.
					<br> - <strong>Comprehensive benchmarking</strong>: Our <a href="https://github.com/YZY-stack/DF40?tab=readme-ov-file">benchmark</a> conduct more than 2,000+ evaluations with 4 standard evaluation protocols, leading to several new findings with insightful analysis.
				</td>
			</tr>
		</center>
	</table>

	<center>
		<img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/table.png"/>
	</center>
	<hr>


	<table align=center width=850px>
		<center><h1>Why doing this? (motivation)</h1></center>
		<tr>
			<td>
				In this work, we aim to address the following challenges in the current deepfake detection research (especially the datasets):
					<br><strong>(1) Forgery Diversity</strong>: Deepfake techniques are commonly referred to as both face forgery (face-swapping and face-reenactment) and entire image synthesis (AIGC, especially face). Most existing datasets only contain partial types of them, with limited forgery methods implemented (e.g., 2 swapping and 2 reenactment methods in FF++);
					<br><strong>(2) Forgery Realism</strong>: The dominated training dataset, such as FF++, contains out-of-date forgery techniques from the past four years. "Honing skills" on these forgeries makes it difficult to guarantee effective detection generalization toward nowadays' SoTA deepfakes;
					<br><strong>(3) Evaluation Protocol</strong>: Most detection works perform evaluations on one type, e.g., face-swapping types only, which hinders the development of universal deepfake detectors.
					<br>To address this dilemma, we construct a highly diverse and large-scale deepfake detection dataset called <strong>DF40</strong>,  which comprises <strong>40</strong> distinct deepfake techniques with <strong>realism</strong>, <strong>diversity</strong>, and <strong>comprehensivity</strong>.
					We also open up several valuable yet previously underexplored research questions to inspire future works.
			</td>
		</tr>
	</table>
	<br>

	<hr>

	<table align=center width=850px>
		<center><h1>Main Results</h1></center>
		<tr>
			<td>
					<br> We conduct main evaluations using four types of protocols, including Cross-forgery evaluation (<strong>Protocol-1</strong>), Cross-domain evaluation (<strong>Protocol-2</strong>), Toward unknown forgery and domain evaluation (<strong>Protocol-3</strong>), and One-Verse-All (OvA) evaluation (<strong>Protocol-4</strong>).
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-1) The results of Protocol-1:</strong></span>
					<center>
					<br> <img class="round" style="width:600px; margin-top: 15; margin-bottom: 10;" src="./images/protocol1.png"/>
					</center>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-2) The results of Protocol-2:</strong></span>
					<center>
					<br> <img class="round" style="width:600px; margin-top: 15; margin-bottom: 10;" src="./images/protocol2.png"/>
					</center>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-3) The results of Protocol-3:</strong></span>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/protocol3.png"/>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-4) The results of Protocol-4:</strong></span>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/protocol4.png"/>

			</td>
		</tr>
	</table>
	<br>

	<hr>


	<table align=center width=850px>
		<center><h1>Additional Results & Analysis</h1></center>
		<tr>
			<td>
					<br> We also provide the following additional results to enlarge our evaluation scope.
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-5) Train on the DF40 "known" methods and test on "unknown" methods of DF40:</strong></span>
					<center>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/train_on_whole_df40.png"/>
					</center>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-6) Train on DF40 and test on non-face AIGCs (GenImage dataset):</strong></span>
					<center>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/non_face_aigc.png"/>
					</center>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-7) Train on previous dataset (FaceForensics++) and test on DF40:</strong></span>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/previous_work_on_df40.png"/>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Results-8) Train on DF40 and test on other deepfake datasets:</strong></span>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/test_other_dfd_data.png"/>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Analysis-1) Logits and confidence distribution analysis for both fake and real classes:</strong></span>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/logit_confidence.png"/>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Analysis-2) t-SNE visualizations for different models on distinct testing data:</strong></span>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/tsne.png"/>
					<br> <span style="color:rgba(11, 128, 0, 0.881)"><strong>(Analysis-3) Frequency-level artifacts analysis for different synthesis methods:</strong></span>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/frequency.png"/>

			</td>
		</tr>
	</table>
	<br>

	<hr>


	<table align=center width=850px>
		<center><h1>Takeaways & Findings</h1></center>
		<tr>
			<td>
				Here, we very briefly outline several key takeaways to encapsulate our contributions and conclusions:
				<br>- 1. The dataset is pivotal in addressing the generalization problem in deepfake detection. To this end, we build a highly diverse deepfake dataset incorporating 40 distinct deepfake techniques, including the most recent ones. The visual example can be seen in the <strong>Supplementary</strong> of our paper;
				<br>- 2. Data domain and forgery method collectively determine the final detection results (see the causal graph in our <strong>main paper</strong> for intuitive understanding);
				<br>- 3. Many recent face-swapping methods (e.g., SimSwap) do NOT involve a blending process but generate all content directly (including the background).
				<br>- 4. Blending is not all you need to detect deepfakes, even face-swapping forgeries.
				<br>- 5. CLIP-large is the most powerful baseline model due to its notable ability to learn robust real-face distribution.
				<br>- 6. The model trained on the face domain (our dataset) can also be somehow applied to the non-face domain (pure AIGC) fakes.
				<br>- 7. There is an urgent need to develop an effective incremental learning framework aiming to produce improved results, creating "1+1>2" results when combining many different forgeries together for training.
			</td>
		</tr>
	</table>
	<br>


	<hr>


	<table align=center width=850px>
		<center><h1>Visual Examples</h1></center>
		<tr>
			<td>
				We show visual examples of FS, FR, EFS, and unknown methods (including FE) from our DF40 dataset, illustrated below.
				<center>
					<br> <img class="round" style="width:800px; margin-top: 15; margin-bottom: 10;" src="./images/examples.png"/>
				</center>
			</td>
		</tr>
	</table>
	<br>

	<hr>

	<table align=center width=800px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./images/df40_intro.png"/></a></td>
			<td>
				<span style="font-size:12pt">
					Zhiyuan Yan, Taiping Yao, Shen Chen, Yandan Zhao, Xinghe Fu, Junwei Zhu, Donghao Luo, Li Yuan, Chengjie Wang, Shouhong Ding, Yunsheng Wu.<br>
					<b>DF40: Toward Next-Generation Deepfake Detection.</b><br>
					<!-- In Conference, 20XX.<br> -->
					(hosted on <a href="https://arxiv.org/abs/2406.13495">ArXiv</a>)<br>
					<!-- (<a href="./resources/camera-ready.png">camera ready</a>)<br> -->
					<span style="font-size:4pt"><a href=""><br></a></span>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>
